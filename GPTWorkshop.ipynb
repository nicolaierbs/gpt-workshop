{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT (Generative Pretrained Transformers) Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine kurze Einführung in die Welt der Sprachmodelle und spezielle GPT-3. Wie können Sie die Welt verändern werden und wie funktionieren sie überhaupt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def continue_text(text):\n",
    "    r = requests.post(\n",
    "        \"https://api.deepai.org/api/text-generator\",\n",
    "        data={\n",
    "            'text': text\n",
    "        },\n",
    "        headers={'api-key': 'quickstart-QUdJIGlzIGNvbWluZy4uLi4K'}\n",
    "    )\n",
    "    return r.json()['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT is going to change the world as we know it. We\\'ll fight hard to help the poor, and if we can do that, then so many more people will be working for it, too. It\\'s a big fight I want to watch for.\"\\n\\nThe Obama administration has proposed a $500 million aid package for Haiti that would include $200 million to help fund community and migrant relief in the port town of Maizomba, a country that has seen devastating cyclone seasons over the last few years.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continue_text('GPT is going to change the world as we know it.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung Sprachmodelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprachmodelle sind in ihrer einfachsten Form auf der Zählung von Wörtern.\n",
    "Die Sprachmodelle können beliebig komplex werden, wenn Kontext berücksichtigt wird.\n",
    "Als Kontext kann das vorherige Wort genutzt werden.\n",
    "Bei Menschen erkennt man das häufig, wenn sie Sprichwörter ergänzen.\n",
    "Auch bei Google sieht man es häufig bei der Vervollständigung von Suchanfragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Marcus currit Lucius currit Marcus et Lucius rident Lucius et Marcus rident'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marcus', 'currit', 'Lucius', 'currit', 'Marcus', 'et', 'Lucius', 'rident', 'Lucius', 'et', 'Marcus', 'rident']\n"
     ]
    }
   ],
   "source": [
    "print(text.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einsatzmöglichkeiten von Sprachmodellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def create_language_model(tokens):\n",
    "    bigrams_language_model = defaultdict(list)\n",
    "    for i in range(0, len(tokens)):\n",
    "        bigrams_language_model[tokens[i-1]].append(tokens[i])\n",
    "    return bigrams_language_model\n",
    "\n",
    "\n",
    "def use_language_model(lm, token):\n",
    "    return random.choice(lm[token])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = create_language_model(text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucius currit et rident currit \n"
     ]
    }
   ],
   "source": [
    "token = 'Lucius'\n",
    "text = ''\n",
    "for i in range(5):\n",
    "    text += token + ' '\n",
    "    token = use_language_model(lm, 'Marcus')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Ansatz ist einfach, führt aber zu mehreren Problemen:\n",
    "1. Alle Wörter müssen abgedeckt sein\n",
    "1. Ergebnisse sind nicht immer grammatikalisch\n",
    "1. Man braucht **VIELE** Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3 im Speziellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was ist an GPT-3 besonders?\n",
    "* Transformer Modell [Arxiv Publikation zu Transfer Learning](https://arxiv.org/pdf/1910.07370.pdf)\n",
    "* 175 Milliarden Parameter\n",
    "* Spezialisierte fine-tuned Modelle für spezifische Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie wird GPT-3 erstellt?\n",
    "1. Großen Textkorpus auswählen (300 Milliarden Wörter)\n",
    "1. Word Embedding für Eingabe erstellen\n",
    "1. Transformer Magic\n",
    "\n",
    "(Animationen von https://jalammar.github.io/how-gpt3-works-visualizations-animations/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Textkorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word Embeddings\n",
    "Word Embeddings sind eine gute Möglichkeit, um Wörter maschinell besser verarbeiten zu können.\n",
    "Mit Word Embeddings werden Wörter als Vektoren dargestellt.\n",
    "Ein häufig verwendetes Tool zum Erstellen von Embeddings ist [word2vec](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/word2vec/word2vec_basic.py) und [fastText](https://fasttext.cc).\n",
    "\n",
    "![http://lifestyletrading101.com/word2vec-deep-learning/](https://i1.wp.com/lifestyletrading101.com/wp-content/uploads/2017/03/word2-vec-king-queen.png \"Embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://jalammar.github.io/how-gpt3-works-visualizations-animations/](https://jalammar.github.io/images/gpt3/06-gpt3-embedding.gif \"Ablauf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprachmodell im Eigenbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
